{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T07:44:32.872688Z",
     "start_time": "2020-04-16T07:44:32.054438Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T07:44:32.956333Z",
     "start_time": "2020-04-16T07:44:32.875420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0423,  0.0632, -0.0175,  ...,  0.0806, -0.0335,  0.1036],\n",
       "        [-0.0469,  0.0462, -0.0763,  ...,  0.0747,  0.0031,  0.0391],\n",
       "        [-0.0893,  0.0443, -0.0561,  ..., -0.0358, -0.0032,  0.0118],\n",
       "        ...,\n",
       "        [ 0.0126, -0.0641,  0.0088,  ...,  0.0512,  0.0392, -0.1226],\n",
       "        [ 0.0011, -0.0091,  0.0948,  ..., -0.0441, -0.0434, -0.0412],\n",
       "        [ 0.0497, -0.0045,  0.0017,  ...,  0.0639, -0.0478, -0.0056]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1636, -0.0047, -0.0737,  ..., -0.0167,  0.0511, -0.0890],\n",
       "        [ 0.0469,  0.2278,  0.0908,  ..., -0.0747, -0.1335, -0.0593],\n",
       "        [-0.0363, -0.0550, -0.0865,  ..., -0.0886,  0.1190,  0.1841],\n",
       "        ...,\n",
       "        [ 0.0617, -0.0483, -0.0846,  ...,  0.0553, -0.1021,  0.0264],\n",
       "        [ 0.0164,  0.0867,  0.1176,  ...,  0.0875, -0.1059, -0.0507],\n",
       "        [-0.1996, -0.0749,  0.0290,  ..., -0.0624,  0.0489,  0.0447]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0585,  0.0637,  0.1080,  ..., -0.1817, -0.0669, -0.0616],\n",
       "        [ 0.1255,  0.0199, -0.1292,  ...,  0.0520,  0.0520, -0.0572],\n",
       "        [ 0.1271,  0.1009, -0.1160,  ..., -0.0662,  0.0811,  0.0907],\n",
       "        ...,\n",
       "        [ 0.0328, -0.0123, -0.0406,  ..., -0.0608,  0.0188,  0.0404],\n",
       "        [ 0.1325, -0.0342,  0.1442,  ..., -0.0628,  0.0576, -0.2505],\n",
       "        [ 0.0906,  0.0835,  0.1371,  ..., -0.0644,  0.0615, -0.0891]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=200\n",
    "learning_rate=0.01\n",
    "epochs=10\n",
    "\n",
    "# 加载数据\n",
    "train_loader=torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data/mnist_data',train=True,download=True,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize((0.1307,),(0.3081,))\n",
    "                  ])),\n",
    "    batch_size=batch_size,shuffle=True\n",
    ")\n",
    "test_loader=torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data/mnist_data',train=False,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize((0.1307,),(0.3081,))\n",
    "                  ])),\n",
    "    batch_size=batch_size,shuffle=True\n",
    ")\n",
    "\n",
    "# 设置 w,b\n",
    "w1,b1=torch.randn(200,784,requires_grad=True),torch.zeros(200,requires_grad=True)\n",
    "w2,b2=torch.randn(200,200,requires_grad=True),torch.zeros(200,requires_grad=True)\n",
    "w3,b3=torch.randn(10,200,requires_grad=True),torch.zeros(10,requires_grad=True)\n",
    "\n",
    "# 凯明初始化\n",
    "torch.nn.init.kaiming_normal_(w1)\n",
    "torch.nn.init.kaiming_normal_(w2)\n",
    "torch.nn.init.kaiming_normal_(w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T07:44:32.963278Z",
     "start_time": "2020-04-16T07:44:32.958295Z"
    }
   },
   "outputs": [],
   "source": [
    "# 前向计算\n",
    "def forward(x):\n",
    "    x=x@w1.t()+b1\n",
    "    x=F.relu(x)\n",
    "    x=x@w2.t()+b2\n",
    "    x=F.relu(x)\n",
    "    x=x@w3.t()+b3\n",
    "    x=F.relu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T07:50:13.725492Z",
     "start_time": "2020-04-16T07:44:32.966271Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 0 [0/60000 (0%)]\t Loss: 2.916919\n",
      "Train epoch: 0 [20000/60000 (33%)]\t Loss: 1.515068\n",
      "Train epoch: 0 [40000/60000 (67%)]\t Loss: 1.159228\n",
      "\n",
      " Test set: Average loss: 0.0034, Accuracy: 7761/10000 (78%)\n",
      "\n",
      "Train epoch: 1 [0/60000 (0%)]\t Loss: 0.670497\n",
      "Train epoch: 1 [20000/60000 (33%)]\t Loss: 0.627831\n",
      "Train epoch: 1 [40000/60000 (67%)]\t Loss: 0.528421\n",
      "\n",
      " Test set: Average loss: 0.0015, Accuracy: 9141/10000 (91%)\n",
      "\n",
      "Train epoch: 2 [0/60000 (0%)]\t Loss: 0.329173\n",
      "Train epoch: 2 [20000/60000 (33%)]\t Loss: 0.237617\n",
      "Train epoch: 2 [40000/60000 (67%)]\t Loss: 0.242257\n",
      "\n",
      " Test set: Average loss: 0.0012, Accuracy: 9280/10000 (93%)\n",
      "\n",
      "Train epoch: 3 [0/60000 (0%)]\t Loss: 0.282852\n",
      "Train epoch: 3 [20000/60000 (33%)]\t Loss: 0.249233\n",
      "Train epoch: 3 [40000/60000 (67%)]\t Loss: 0.254817\n",
      "\n",
      " Test set: Average loss: 0.0011, Accuracy: 9362/10000 (94%)\n",
      "\n",
      "Train epoch: 4 [0/60000 (0%)]\t Loss: 0.187555\n",
      "Train epoch: 4 [20000/60000 (33%)]\t Loss: 0.176362\n",
      "Train epoch: 4 [40000/60000 (67%)]\t Loss: 0.239523\n",
      "\n",
      " Test set: Average loss: 0.0010, Accuracy: 9403/10000 (94%)\n",
      "\n",
      "Train epoch: 5 [0/60000 (0%)]\t Loss: 0.238029\n",
      "Train epoch: 5 [20000/60000 (33%)]\t Loss: 0.101263\n",
      "Train epoch: 5 [40000/60000 (67%)]\t Loss: 0.190027\n",
      "\n",
      " Test set: Average loss: 0.0009, Accuracy: 9431/10000 (94%)\n",
      "\n",
      "Train epoch: 6 [0/60000 (0%)]\t Loss: 0.128229\n",
      "Train epoch: 6 [20000/60000 (33%)]\t Loss: 0.179234\n",
      "Train epoch: 6 [40000/60000 (67%)]\t Loss: 0.201755\n",
      "\n",
      " Test set: Average loss: 0.0009, Accuracy: 9473/10000 (95%)\n",
      "\n",
      "Train epoch: 7 [0/60000 (0%)]\t Loss: 0.167640\n",
      "Train epoch: 7 [20000/60000 (33%)]\t Loss: 0.076947\n",
      "Train epoch: 7 [40000/60000 (67%)]\t Loss: 0.240810\n",
      "\n",
      " Test set: Average loss: 0.0008, Accuracy: 9505/10000 (95%)\n",
      "\n",
      "Train epoch: 8 [0/60000 (0%)]\t Loss: 0.224658\n",
      "Train epoch: 8 [20000/60000 (33%)]\t Loss: 0.138643\n",
      "Train epoch: 8 [40000/60000 (67%)]\t Loss: 0.107201\n",
      "\n",
      " Test set: Average loss: 0.0008, Accuracy: 9529/10000 (95%)\n",
      "\n",
      "Train epoch: 9 [0/60000 (0%)]\t Loss: 0.080994\n",
      "Train epoch: 9 [20000/60000 (33%)]\t Loss: 0.110205\n",
      "Train epoch: 9 [40000/60000 (67%)]\t Loss: 0.109439\n",
      "\n",
      " Test set: Average loss: 0.0008, Accuracy: 9542/10000 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer=optim.SGD([w1,b1,w2,b2,w3,b3],lr=learning_rate)\n",
    "criteon=nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.view(-1, 28*28)\n",
    "\n",
    "        logits = forward(data)\n",
    "        loss = criteon(logits, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # print(w1.grad.norm(), w2.grad.norm())\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 ==0: \n",
    "            print(\"Train epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}\".format(\n",
    "                epoch,batch_idx * len(data),len(train_loader.dataset),\n",
    "                100.*batch_idx/len(train_loader),loss.item()))\n",
    "        \n",
    "    test_loss=0 \n",
    "    correct=0 \n",
    "    for data,target in test_loader:\n",
    "        data=data.view(-1,28*28)\n",
    "        logits=forward(data)\n",
    "        test_loss+=criteon(logits,target).item()\n",
    "        \n",
    "        pred=logits.data.max(1)[1]\n",
    "        correct+=pred.eq(target.data).sum()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\n Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss,correct,len(test_loader.dataset),\n",
    "        100.*correct/len(test_loader.dataset)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
