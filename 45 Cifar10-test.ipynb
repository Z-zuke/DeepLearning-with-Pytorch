{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T08:26:08.589105Z",
     "start_time": "2020-04-19T08:26:06.699412Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn,optim\n",
    "from torchvision import datasets,transforms\n",
    "\n",
    "from utils import Lenet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T08:26:08.637974Z",
     "start_time": "2020-04-19T08:26:08.597084Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    batchsz=128\n",
    "    epochs=100\n",
    "    \n",
    "    cifar_train=datasets.CIFAR10('./data/cifar',train=True,download=True,\n",
    "                                transform=transforms.Compose([\n",
    "                                    transforms.Resize((32,32)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                                                        std=[0.229,0.224,0.225])\n",
    "                                ]))\n",
    "    cifar_train=DataLoader(cifar_train,batch_size=batchsz,shuffle=True)\n",
    "    \n",
    "    cifar_test=datasets.CIFAR10('./data/cifar',train=False,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.Resize((32,32)),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                                                       std=[0.229,0.224,0.225])\n",
    "                               ]))\n",
    "    cifar_test=DataLoader(cifar_test,batch_size=batchsz,shuffle=True)\n",
    "    \n",
    "    \n",
    "    x,label=iter(cifar_train).next()\n",
    "    print('x:',x.shape,'label:',label.shape)\n",
    "    \n",
    "    \n",
    "    device=torch.device('cuda')\n",
    "    model=Lenet5().to(device)\n",
    "    \n",
    "    criteon=nn.CrossEntropyLoss().to(device)\n",
    "    optimizer=optim.Adam(model.parameters(),lr=1e-3)\n",
    "    print(model)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        for batchidx,(x,label) in enumerate(cifar_train):\n",
    "            x,label=x.to(device),label.to(device)\n",
    "            \n",
    "            logits=model(x)\n",
    "            # logits: [b,10]\n",
    "            # label: [b]\n",
    "            # loss: tensor scalar\n",
    "            loss=criteon(logits,label)\n",
    "            \n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('epoch={} loss={}'.format(epoch,loss.item()))\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_correct=0 \n",
    "            total_num=0 \n",
    "            for x,label in cifar_test:\n",
    "                x,label=x.to(device),label.to(device)\n",
    "                # [b,10]\n",
    "                logits=model(x)\n",
    "                pred=logits.argmax(dim=1)\n",
    "                # [b] vs [b] => scalar tensor\n",
    "                correct=torch.eq(pred,label).float().sum().item()\n",
    "                total_correct+=correct\n",
    "                total_num+=x.size(0)\n",
    "                # print(correct)\n",
    "            \n",
    "            acc=total_correct / total_num\n",
    "            print('epoch={} test acc={}'.format(epoch,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T09:05:22.959627Z",
     "start_time": "2020-04-19T08:26:08.640967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "x: torch.Size([128, 3, 32, 32]) label: torch.Size([128])\n",
      "Lenet5(\n",
      "  (conv_unit): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc_unit): Sequential(\n",
      "    (0): Linear(in_features=800, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch=0 loss=1.2465145587921143\n",
      "epoch=0 test acc=0.5319\n",
      "epoch=1 loss=1.4509888887405396\n",
      "epoch=1 test acc=0.5803\n",
      "epoch=2 loss=0.9731515049934387\n",
      "epoch=2 test acc=0.6113\n",
      "epoch=3 loss=1.387157917022705\n",
      "epoch=3 test acc=0.6242\n",
      "epoch=4 loss=1.0898581743240356\n",
      "epoch=4 test acc=0.6304\n",
      "epoch=5 loss=0.7639704942703247\n",
      "epoch=5 test acc=0.6474\n",
      "epoch=6 loss=0.7387717962265015\n",
      "epoch=6 test acc=0.6489\n",
      "epoch=7 loss=0.826728343963623\n",
      "epoch=7 test acc=0.6452\n",
      "epoch=8 loss=1.0226852893829346\n",
      "epoch=8 test acc=0.6537\n",
      "epoch=9 loss=0.8672925233840942\n",
      "epoch=9 test acc=0.6532\n",
      "epoch=10 loss=0.7108084559440613\n",
      "epoch=10 test acc=0.6643\n",
      "epoch=11 loss=0.8110954165458679\n",
      "epoch=11 test acc=0.6641\n",
      "epoch=12 loss=0.8017876744270325\n",
      "epoch=12 test acc=0.6652\n",
      "epoch=13 loss=0.9663180112838745\n",
      "epoch=13 test acc=0.6742\n",
      "epoch=14 loss=0.596464991569519\n",
      "epoch=14 test acc=0.6663\n",
      "epoch=15 loss=0.9696779251098633\n",
      "epoch=15 test acc=0.6568\n",
      "epoch=16 loss=0.9456466436386108\n",
      "epoch=16 test acc=0.6611\n",
      "epoch=17 loss=0.7785412669181824\n",
      "epoch=17 test acc=0.6614\n",
      "epoch=18 loss=0.4657672941684723\n",
      "epoch=18 test acc=0.6635\n",
      "epoch=19 loss=0.7835187911987305\n",
      "epoch=19 test acc=0.6589\n",
      "epoch=20 loss=0.8041976690292358\n",
      "epoch=20 test acc=0.6622\n",
      "epoch=21 loss=0.69977867603302\n",
      "epoch=21 test acc=0.6607\n",
      "epoch=22 loss=0.6111941337585449\n",
      "epoch=22 test acc=0.6598\n",
      "epoch=23 loss=0.5599021315574646\n",
      "epoch=23 test acc=0.6635\n",
      "epoch=24 loss=0.7511142492294312\n",
      "epoch=24 test acc=0.6606\n",
      "epoch=25 loss=0.6390549540519714\n",
      "epoch=25 test acc=0.6563\n",
      "epoch=26 loss=0.48980021476745605\n",
      "epoch=26 test acc=0.6543\n",
      "epoch=27 loss=0.6720575094223022\n",
      "epoch=27 test acc=0.6593\n",
      "epoch=28 loss=0.5922242999076843\n",
      "epoch=28 test acc=0.6543\n",
      "epoch=29 loss=0.4318504333496094\n",
      "epoch=29 test acc=0.6575\n",
      "epoch=30 loss=0.49496954679489136\n",
      "epoch=30 test acc=0.6532\n",
      "epoch=31 loss=0.707030177116394\n",
      "epoch=31 test acc=0.6553\n",
      "epoch=32 loss=0.69629967212677\n",
      "epoch=32 test acc=0.6534\n",
      "epoch=33 loss=0.6813956499099731\n",
      "epoch=33 test acc=0.6518\n",
      "epoch=34 loss=0.7571333646774292\n",
      "epoch=34 test acc=0.6543\n",
      "epoch=35 loss=0.4882076680660248\n",
      "epoch=35 test acc=0.6475\n",
      "epoch=36 loss=0.5206940770149231\n",
      "epoch=36 test acc=0.6496\n",
      "epoch=37 loss=0.48569464683532715\n",
      "epoch=37 test acc=0.6497\n",
      "epoch=38 loss=0.3456837236881256\n",
      "epoch=38 test acc=0.6505\n",
      "epoch=39 loss=0.530620276927948\n",
      "epoch=39 test acc=0.6485\n",
      "epoch=40 loss=0.40960463881492615\n",
      "epoch=40 test acc=0.6449\n",
      "epoch=41 loss=0.44556933641433716\n",
      "epoch=41 test acc=0.6392\n",
      "epoch=42 loss=0.47891750931739807\n",
      "epoch=42 test acc=0.6472\n",
      "epoch=43 loss=0.6265395283699036\n",
      "epoch=43 test acc=0.6461\n",
      "epoch=44 loss=0.591747522354126\n",
      "epoch=44 test acc=0.6388\n",
      "epoch=45 loss=0.43830347061157227\n",
      "epoch=45 test acc=0.6413\n",
      "epoch=46 loss=0.441474974155426\n",
      "epoch=46 test acc=0.6463\n",
      "epoch=47 loss=0.5997506380081177\n",
      "epoch=47 test acc=0.6458\n",
      "epoch=48 loss=0.6626282334327698\n",
      "epoch=48 test acc=0.6393\n",
      "epoch=49 loss=0.4814234673976898\n",
      "epoch=49 test acc=0.6365\n",
      "epoch=50 loss=0.48839807510375977\n",
      "epoch=50 test acc=0.6398\n",
      "epoch=51 loss=0.33214327692985535\n",
      "epoch=51 test acc=0.634\n",
      "epoch=52 loss=0.30747154355049133\n",
      "epoch=52 test acc=0.6393\n",
      "epoch=53 loss=0.4804742932319641\n",
      "epoch=53 test acc=0.6428\n",
      "epoch=54 loss=0.5318235158920288\n",
      "epoch=54 test acc=0.6367\n",
      "epoch=55 loss=0.5254716873168945\n",
      "epoch=55 test acc=0.6362\n",
      "epoch=56 loss=0.34033674001693726\n",
      "epoch=56 test acc=0.638\n",
      "epoch=57 loss=0.4544670581817627\n",
      "epoch=57 test acc=0.6345\n",
      "epoch=58 loss=0.29946815967559814\n",
      "epoch=58 test acc=0.6335\n",
      "epoch=59 loss=0.29799336194992065\n",
      "epoch=59 test acc=0.6354\n",
      "epoch=60 loss=0.5233237147331238\n",
      "epoch=60 test acc=0.6306\n",
      "epoch=61 loss=0.41002774238586426\n",
      "epoch=61 test acc=0.6378\n",
      "epoch=62 loss=0.3510257601737976\n",
      "epoch=62 test acc=0.6348\n",
      "epoch=63 loss=0.5244277715682983\n",
      "epoch=63 test acc=0.6389\n",
      "epoch=64 loss=0.45121389627456665\n",
      "epoch=64 test acc=0.6317\n",
      "epoch=65 loss=0.3560170531272888\n",
      "epoch=65 test acc=0.6329\n",
      "epoch=66 loss=0.27447938919067383\n",
      "epoch=66 test acc=0.6292\n",
      "epoch=67 loss=0.40203800797462463\n",
      "epoch=67 test acc=0.6282\n",
      "epoch=68 loss=0.39662784337997437\n",
      "epoch=68 test acc=0.6288\n",
      "epoch=69 loss=0.3711358904838562\n",
      "epoch=69 test acc=0.6258\n",
      "epoch=70 loss=0.3218585252761841\n",
      "epoch=70 test acc=0.6299\n",
      "epoch=71 loss=0.31097131967544556\n",
      "epoch=71 test acc=0.6322\n",
      "epoch=72 loss=0.3782646656036377\n",
      "epoch=72 test acc=0.6331\n",
      "epoch=73 loss=0.4524380564689636\n",
      "epoch=73 test acc=0.6252\n",
      "epoch=74 loss=0.39267247915267944\n",
      "epoch=74 test acc=0.6227\n",
      "epoch=75 loss=0.26475054025650024\n",
      "epoch=75 test acc=0.6254\n",
      "epoch=76 loss=0.2770766317844391\n",
      "epoch=76 test acc=0.6291\n",
      "epoch=77 loss=0.261030375957489\n",
      "epoch=77 test acc=0.6281\n",
      "epoch=78 loss=0.23689499497413635\n",
      "epoch=78 test acc=0.6303\n",
      "epoch=79 loss=0.4717368185520172\n",
      "epoch=79 test acc=0.6236\n",
      "epoch=80 loss=0.23940518498420715\n",
      "epoch=80 test acc=0.6255\n",
      "epoch=81 loss=0.3455568552017212\n",
      "epoch=81 test acc=0.6312\n",
      "epoch=82 loss=0.29449427127838135\n",
      "epoch=82 test acc=0.6229\n",
      "epoch=83 loss=0.2602495551109314\n",
      "epoch=83 test acc=0.6217\n",
      "epoch=84 loss=0.19739975035190582\n",
      "epoch=84 test acc=0.624\n",
      "epoch=85 loss=0.3304848074913025\n",
      "epoch=85 test acc=0.6278\n",
      "epoch=86 loss=0.39397406578063965\n",
      "epoch=86 test acc=0.6231\n",
      "epoch=87 loss=0.3395639657974243\n",
      "epoch=87 test acc=0.6254\n",
      "epoch=88 loss=0.45895761251449585\n",
      "epoch=88 test acc=0.6256\n",
      "epoch=89 loss=0.3080468773841858\n",
      "epoch=89 test acc=0.623\n",
      "epoch=90 loss=0.3187260031700134\n",
      "epoch=90 test acc=0.6273\n",
      "epoch=91 loss=0.23429672420024872\n",
      "epoch=91 test acc=0.6221\n",
      "epoch=92 loss=0.2563837766647339\n",
      "epoch=92 test acc=0.6264\n",
      "epoch=93 loss=0.26716601848602295\n",
      "epoch=93 test acc=0.6279\n",
      "epoch=94 loss=0.2303827553987503\n",
      "epoch=94 test acc=0.625\n",
      "epoch=95 loss=0.2858596444129944\n",
      "epoch=95 test acc=0.6255\n",
      "epoch=96 loss=0.49860554933547974\n",
      "epoch=96 test acc=0.621\n",
      "epoch=97 loss=0.17763477563858032\n",
      "epoch=97 test acc=0.6195\n",
      "epoch=98 loss=0.40408381819725037\n",
      "epoch=98 test acc=0.6242\n",
      "epoch=99 loss=0.33368200063705444\n",
      "epoch=99 test acc=0.6202\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
