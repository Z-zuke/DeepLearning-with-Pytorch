{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [VAE的原理](https://www.cnblogs.com/huangshiyu13/p/6209016.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:38:06.623264Z",
     "start_time": "2020-04-22T03:38:05.862883Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn,optim\n",
    "from torchvision import transforms,datasets\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:38:06.638213Z",
     "start_time": "2020-04-22T03:38:06.625598Z"
    }
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(VAE,self).__init__()\n",
    "        \n",
    "        # VAE的编码器会产生两个向量:一个是均值向量，一个是标准差向量。\n",
    "        # [b,784] => [b,20]\n",
    "        # u: [b,10]\n",
    "        # sigma: [b,10]\n",
    "        self.encoder=nn.Sequential(\n",
    "            nn.Linear(784,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,20),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # [b,10] => [b,784]\n",
    "        self.decoder=nn.Sequential(\n",
    "            nn.Linear(10,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        param x: [b,1,28,28]\n",
    "        return x \n",
    "        \"\"\"\n",
    "        batchsz=x.size(0)\n",
    "        # flatten\n",
    "        x=x.view(batchsz,-1)\n",
    "        # encoder\n",
    "        # [b,20] include mean and sigma\n",
    "        h_=self.encoder(x)\n",
    "        \n",
    "        # [b,20] => u=[b,10], sigma=[b,10]\n",
    "        mu,sigma=h_.chunk(2,dim=1)\n",
    "        # reparametrize trick, epison~N(0,1)\n",
    "        epison=torch.randn_like(sigma)\n",
    "        h=mu+sigma*epison\n",
    "        \n",
    "        # decoder\n",
    "        x_hat=self.decoder(h)\n",
    "        # reshape\n",
    "        x_hat=x.view(batchsz,1,28,28)\n",
    "        \n",
    "        # KL divegence\n",
    "        kld=0.5*torch.sum(\n",
    "            torch.pow(mu,2)+torch.pow(sigma,2)-torch.log(1e-8+torch.pow(sigma,2))-1 \n",
    "        )  #/ (batchsz*28*28)\n",
    "        \n",
    "        return x_hat,kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:38:06.660220Z",
     "start_time": "2020-04-22T03:38:06.640955Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    batch_size=32 \n",
    "    epochs=100\n",
    "    learning_rate=1e-3 \n",
    "    \n",
    "    train_db=datasets.MNIST('./data/mnist_data',train=True,download=True,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize((0.1307,),(0.3081,))\n",
    "                  ]))\n",
    "    train_loader=torch.utils.data.DataLoader(train_db,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "    test_db=datasets.MNIST('./data/mnist_data',train=False,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize((0.1307,),(0.3081,))\n",
    "                  ]))\n",
    "    test_loader=torch.utils.data.DataLoader(test_db,batch_size=batch_size,shuffle=True)\n",
    "    \n",
    "    \n",
    "    x,_ =iter(train_loader).next()\n",
    "    print('x:',x.shape)\n",
    "    \n",
    "    device=torch.device('cuda')\n",
    "    model=VAE().to(device)\n",
    "    criteon=nn.MSELoss()\n",
    "    optimizer=optim.Adam(model.parameters(),lr=learning_rate)\n",
    "    print(model)\n",
    "    \n",
    "    \n",
    "    viz=visdom.Visdom()\n",
    "    for epoch in range(epochs):\n",
    "        for batchidx,(x,_) in enumerate(train_loader):\n",
    "            # [b,1,28,28]\n",
    "            x=x.to(device)\n",
    "            \n",
    "            x_hat,kld=model(x)   # logits\n",
    "            reconstruct_loss=criteon(x_hat,x)\n",
    "            \n",
    "            # 损失函数可以把这两方面进行加和。\n",
    "            # 一方面，是图片的重构误差，可以用平均平方误差来度量\n",
    "            # 另一方面，用KL散度来度量潜在变量的分布和单位高斯分布的差异\n",
    "            loss=reconstruct_loss+1.0*kld\n",
    "            \n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print('epoch={} loss={} kld={}'.format(epoch,loss.item(),kld))\n",
    "        \n",
    "        x,_=iter(test_loader).next()\n",
    "        x=x.to(device)\n",
    "        with torch.no_grad():\n",
    "            x_hat,kld=model(x)\n",
    "            \n",
    "        viz.images(x,nrow=8,win='x',opts=dict(title='x'))\n",
    "        viz.images(x_hat,nrow=8,win='x_hat',opts=dict(title='x_hat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T04:25:40.776850Z",
     "start_time": "2020-04-22T03:38:06.662154Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([32, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=20, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=784, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n",
      "epoch=0 loss=2.069458105324884e-06 kld=2.069458105324884e-06\n",
      "epoch=1 loss=1.8934547370008659e-06 kld=1.8934547370008659e-06\n",
      "epoch=2 loss=8.11341124062892e-07 kld=8.11341124062892e-07\n",
      "epoch=3 loss=8.413691716668836e-07 kld=8.413691716668836e-07\n",
      "epoch=4 loss=5.489101226885396e-07 kld=5.489101226885396e-07\n",
      "epoch=5 loss=2.53642838288215e-07 kld=2.53642838288215e-07\n",
      "epoch=6 loss=6.020738965162309e-07 kld=6.020738965162309e-07\n",
      "epoch=7 loss=6.033544650563272e-07 kld=6.033544650563272e-07\n",
      "epoch=8 loss=7.684361236215409e-08 kld=7.684361236215409e-08\n",
      "epoch=9 loss=1.2637951840588357e-07 kld=1.2637951840588357e-07\n",
      "epoch=10 loss=7.601682483482364e-08 kld=7.601682483482364e-08\n",
      "epoch=11 loss=2.3501401358316798e-07 kld=2.3501401358316798e-07\n",
      "epoch=12 loss=2.0312097603891743e-07 kld=2.0312097603891743e-07\n",
      "epoch=13 loss=4.5406725490693134e-08 kld=4.5406725490693134e-08\n",
      "epoch=14 loss=4.1438389075665327e-07 kld=4.1438389075665327e-07\n",
      "epoch=15 loss=2.662703479927586e-07 kld=2.662703479927586e-07\n",
      "epoch=16 loss=9.240525145060019e-08 kld=9.240525145060019e-08\n",
      "epoch=17 loss=2.2000119059839562e-08 kld=2.2000119059839562e-08\n",
      "epoch=18 loss=5.523788217942638e-07 kld=5.523788217942638e-07\n",
      "epoch=19 loss=5.382426593314449e-08 kld=5.382426593314449e-08\n",
      "epoch=20 loss=8.825302870718588e-07 kld=8.825302870718588e-07\n",
      "epoch=21 loss=8.507822002457033e-09 kld=8.507822002457033e-09\n",
      "epoch=22 loss=3.9407773044786154e-08 kld=3.9407773044786154e-08\n",
      "epoch=23 loss=5.374586464768072e-08 kld=5.374586464768072e-08\n",
      "epoch=24 loss=3.627168609909859e-08 kld=3.627168609909859e-08\n",
      "epoch=25 loss=9.181129456692361e-08 kld=9.181129456692361e-08\n",
      "epoch=26 loss=2.504093572497368e-07 kld=2.504093572497368e-07\n",
      "epoch=27 loss=1.0025734553664734e-07 kld=1.0025734553664734e-07\n",
      "epoch=28 loss=1.7151064568565744e-08 kld=1.7151064568565744e-08\n",
      "epoch=29 loss=2.2342476313497173e-07 kld=2.2342476313497173e-07\n",
      "epoch=30 loss=2.7492785648064455e-07 kld=2.7492785648064455e-07\n",
      "epoch=31 loss=1.186485931725656e-08 kld=1.186485931725656e-08\n",
      "epoch=32 loss=5.302598893308641e-08 kld=5.302598893308641e-08\n",
      "epoch=33 loss=3.182177010785381e-08 kld=3.182177010785381e-08\n",
      "epoch=34 loss=9.930939626201507e-09 kld=9.930939626201507e-09\n",
      "epoch=35 loss=9.396379141435318e-08 kld=9.396379141435318e-08\n",
      "epoch=36 loss=8.008898788602892e-08 kld=8.008898788602892e-08\n",
      "epoch=37 loss=1.6120908696848346e-07 kld=1.6120908696848346e-07\n",
      "epoch=38 loss=3.838379214471388e-08 kld=3.838379214471388e-08\n",
      "epoch=39 loss=7.306368132731222e-08 kld=7.306368132731222e-08\n",
      "epoch=40 loss=7.858271544591844e-08 kld=7.858271544591844e-08\n",
      "epoch=41 loss=2.5428432692820024e-08 kld=2.5428432692820024e-08\n",
      "epoch=42 loss=2.0638772468828392e-08 kld=2.0638772468828392e-08\n",
      "epoch=43 loss=1.652622358960798e-07 kld=1.652622358960798e-07\n",
      "epoch=44 loss=7.167857418721724e-09 kld=7.167857418721724e-09\n",
      "epoch=45 loss=1.7317372424940913e-08 kld=1.7317372424940913e-08\n",
      "epoch=46 loss=1.3941328091959804e-08 kld=1.3941328091959804e-08\n",
      "epoch=47 loss=8.536331641550987e-09 kld=8.536331641550987e-09\n",
      "epoch=48 loss=4.038423639940447e-08 kld=4.038423639940447e-08\n",
      "epoch=49 loss=6.7473369114168236e-09 kld=6.7473369114168236e-09\n",
      "epoch=50 loss=5.27907850766951e-09 kld=5.27907850766951e-09\n",
      "epoch=51 loss=1.1159239754476857e-08 kld=1.1159239754476857e-08\n",
      "epoch=52 loss=5.9039198418986416e-08 kld=5.9039198418986416e-08\n",
      "epoch=53 loss=6.200897573194197e-09 kld=6.200897573194197e-09\n",
      "epoch=54 loss=6.396665241936716e-08 kld=6.396665241936716e-08\n",
      "epoch=55 loss=9.26333321160655e-09 kld=9.26333321160655e-09\n",
      "epoch=56 loss=8.645619331559828e-09 kld=8.645619331559828e-09\n",
      "epoch=57 loss=8.819054819753092e-09 kld=8.819054819753092e-09\n",
      "epoch=58 loss=2.486773809096121e-08 kld=2.486773809096121e-08\n",
      "epoch=59 loss=2.865242265670531e-09 kld=2.865242265670531e-09\n",
      "epoch=60 loss=1.3309359836455315e-08 kld=1.3309359836455315e-08\n",
      "epoch=61 loss=5.621196841332221e-09 kld=5.621196841332221e-09\n",
      "epoch=62 loss=2.2142669919844593e-09 kld=2.2142669919844593e-09\n",
      "epoch=63 loss=9.37499677888809e-09 kld=9.37499677888809e-09\n",
      "epoch=64 loss=2.0303781766983775e-08 kld=2.0303781766983775e-08\n",
      "epoch=65 loss=6.837618027333292e-09 kld=6.837618027333292e-09\n",
      "epoch=66 loss=2.6559323629271603e-08 kld=2.6559323629271603e-08\n",
      "epoch=67 loss=6.566774235494677e-09 kld=6.566774235494677e-09\n",
      "epoch=68 loss=1.0733967314990878e-07 kld=1.0733967314990878e-07\n",
      "epoch=69 loss=6.402842700481415e-09 kld=6.402842700481415e-09\n",
      "epoch=70 loss=1.1389694520858029e-08 kld=1.1389694520858029e-08\n",
      "epoch=71 loss=1.7984979061580475e-09 kld=1.7984979061580475e-09\n",
      "epoch=72 loss=3.4710772034429738e-09 kld=3.4710772034429738e-09\n",
      "epoch=73 loss=2.8578773125786938e-08 kld=2.8578773125786938e-08\n",
      "epoch=74 loss=1.991177178695125e-08 kld=1.991177178695125e-08\n",
      "epoch=75 loss=1.883790012868758e-08 kld=1.883790012868758e-08\n",
      "epoch=76 loss=1.2202225896373875e-08 kld=1.2202225896373875e-08\n",
      "epoch=77 loss=9.921436117110716e-09 kld=9.921436117110716e-09\n",
      "epoch=78 loss=1.5575894352082287e-08 kld=1.5575894352082287e-08\n",
      "epoch=79 loss=3.5756133609510243e-09 kld=3.5756133609510243e-09\n",
      "epoch=80 loss=1.207393207636187e-08 kld=1.207393207636187e-08\n",
      "epoch=81 loss=2.801095133619924e-09 kld=2.801095133619924e-09\n",
      "epoch=82 loss=4.725036362174251e-08 kld=4.725036362174251e-08\n",
      "epoch=83 loss=1.5618660142990848e-08 kld=1.5618660142990848e-08\n",
      "epoch=84 loss=8.959228026128585e-09 kld=8.959228026128585e-09\n",
      "epoch=85 loss=6.348198855476994e-09 kld=6.348198855476994e-09\n",
      "epoch=86 loss=1.2092937762275824e-09 kld=1.2092937762275824e-09\n",
      "epoch=87 loss=4.088791083489696e-09 kld=4.088791083489696e-09\n",
      "epoch=88 loss=5.7171799738853224e-08 kld=5.7171799738853224e-08\n",
      "epoch=89 loss=2.9080071684006725e-09 kld=2.9080071684006725e-09\n",
      "epoch=90 loss=3.709847362642904e-08 kld=3.709847362642904e-08\n",
      "epoch=91 loss=6.528761087309931e-09 kld=6.528761087309931e-09\n",
      "epoch=92 loss=5.687720072700131e-09 kld=5.687720072700131e-09\n",
      "epoch=93 loss=2.703686385885362e-09 kld=2.703686385885362e-09\n",
      "epoch=94 loss=2.002105858878167e-08 kld=2.002105858878167e-08\n",
      "epoch=95 loss=1.8795134337779018e-08 kld=1.8795134337779018e-08\n",
      "epoch=96 loss=6.203273450466895e-09 kld=6.203273450466895e-09\n",
      "epoch=97 loss=4.528318164886969e-09 kld=4.528318164886969e-09\n",
      "epoch=98 loss=5.271950875851417e-09 kld=5.271950875851417e-09\n",
      "epoch=99 loss=9.46290246162107e-09 kld=9.46290246162107e-09\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
